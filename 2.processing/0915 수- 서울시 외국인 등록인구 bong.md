## 9/15 수

#### 서울특별시 외국인 등록인구

```python
from pyspark.sql.functions import regexp_replace
from pyspark.sql.types import IntegerType

df = spark.read.option("headers", "true").csv("data/foreigner/seoul_foreigners_by_age_gender.csv")
df = df.withColumn('_c4', regexp_replace('_c4', ',' ,'')) 
df = df.withColumn('_c4', df['_c4'].cast("integer"))

df = df.withColumn('_c5', regexp_replace('_c5', ',' ,'')) 
df = df.withColumn('_c5', df['_c5'].cast("integer"))

df = df.withColumn('_c6', regexp_replace('_c6', ',' ,'')) 
df = df.withColumn('_c6', df['_c6'].cast("integer"))

df = df.withColumn('_c7', regexp_replace('_c7', ',' ,'')) 
df = df.withColumn('_c7', df['_c7'].cast("integer"))

df = df.withColumn('_c8', regexp_replace('_c8', ',' ,'')) 
df = df.withColumn('_c8', df['_c8'].cast("integer"))

df = df.withColumn('_c9', regexp_replace('_c9', ',' ,'')) 
df = df.withColumn('_c9', df['_c9'].cast("integer"))

df = df.withColumn('_c10', regexp_replace('_c10', ',' ,'')) 
df = df.withColumn('_c10', df['_c10'].cast("integer"))

df = df.withColumn('_c11', regexp_replace('_c11', ',' ,'')) 
df = df.withColumn('_c11', df['_c11'].cast("integer"))

df = df.withColumn('_c12', regexp_replace('_c12', ',' ,'')) 
df = df.withColumn('_c12', df['_c11'].cast("integer"))

df = df.withColumn('_c13', regexp_replace('_c13', ',' ,'')) 
df = df.withColumn('_c13', df['_c13'].cast("integer"))

df = df.withColumn('_c14', regexp_replace('_c14', ',' ,'')) 
df = df.withColumn('_c14', df['_c14'].cast("integer"))

df = df.withColumn('_c15', regexp_replace('_c15', ',' ,'')) 
df = df.withColumn('_c15', df['_c15'].cast("integer"))

df = df.withColumn('_c16', regexp_replace('_c16', ',' ,'')) 
df = df.withColumn('_c16', df['_c16'].cast("integer"))

df = df.withColumn('_c17', regexp_replace('_c17', ',' ,'')) 
df = df.withColumn('_c17', df['_c17'].cast("integer"))

df = df.withColumn('_c18', regexp_replace('_c18', ',' ,'')) 
df = df.withColumn('_c18', df['_c18'].cast("integer"))

df = df.withColumn('_c19', regexp_replace('_c19', ',' ,'')) 
df = df.withColumn('_c19', df['_c19'].cast("integer"))
```



```
df = df.toDF('index', '연도', '행정구역(구별)','성별', '합계', '0004','0509','1014','1519','2024','2529','3034','3539','4044','4549','5054','5559','6064','6569','7074','7579','8084','8589','9094','9599','100세이상')

df = df.where(col('연도') != '기간')
df = df.where(col('성별') != '계')
```



```
df = df.withColumn('10세미만', col('0004') + col('0509')).withColumn('10대', col('1014') + col('1519'))\
.withColumn('20대', col('2024') + col('2529')).withColumn('30대', col('3034') + col('3539'))\
.withColumn('40대', col('4044') + col('4549')).withColumn('50대', col('5054') + col('5559'))\
.withColumn('60대', col('6064') + col('6569')).withColumn('70대', col('7074') + col('7579'))\
.withColumn('80대', col('8084') + col('8589')).withColumn('90대', col('9094') + col('9599'))
```



```
df = df.na.replace(['-'], ['0'], '9094')
df = df.na.replace(['-'], ['0'], '9599')
df = df.na.replace(['-'], ['0'], '100세이상')

```



```
df.createOrReplaceTempView("table")
spark.sql("SELECT *, NVL(7579, 0) FROM table")

from pyspark.sql.types import StringType,BooleanType,DateType,IntegerType
df2 = df.withColumn("7579_2",col("7579").cast(IntegerType()))\
.withColumn("8084_2",col("8084").cast(IntegerType()))\
.withColumn("8589_2",col("8589").cast(IntegerType()))\
.withColumn("9094_2",col("9094").cast(IntegerType()))\
.withColumn("9599_2",col("9599").cast(IntegerType()))\
.withColumn("100세이상_2",col("100세이상").cast(IntegerType()))

```

